{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5fd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "conn = sqlite3.connect(\"etl/soccer_analysis.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a11e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TOOL: name='scatter_plot' args_schema={'properties': {'input_file_name': {'title': 'Input File Name', 'type': 'string'}, 'title': {'title': 'Title', 'type': 'string'}, 'x': {'title': 'X', 'type': 'string'}, 'y': {'title': 'Y', 'type': 'string'}, 'output_file_name': {'title': 'Output File Name', 'type': 'string'}}, 'required': ['input_file_name', 'title', 'x', 'y', 'output_file_name'], 'title': 'scatter_plotArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4cdd1b0>\n",
      "‚úÖ TOOL: name='query' description='\\n            Execute an SQL query and save the result as a CSV file.\\n            Args:\\n                query (str): SQL query to execute.\\n                file_name (str): Name of the CSV file to save results.\\n            Returns:\\n                str: File name if successful, or error message if failed.\\n            ' args_schema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'file_name': {'title': 'File Name', 'type': 'string'}}, 'required': ['query', 'file_name'], 'title': 'queryArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4d11480>\n",
      "‚úÖ TOOL: name='get_schema_info' description='\\n            Retrieve the schema information for a specified table.\\n            Args:\\n                table_name (str): Name of the table.\\n            Returns:\\n                str: Schema information or error message.\\n            ' args_schema={'properties': {'table_name': {'title': 'Table Name', 'type': 'string'}}, 'required': ['table_name'], 'title': 'get_schema_infoArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4d22830>\n",
      "‚úÖ TOOL: name='get_metrics_info' description='\\n            Get descriptions for a list of metric names using the metrics resource.\\n            Args:\\n                metrics (List[str]): List of metric names.\\n            Returns:\\n                str: Metric descriptions, one per line.\\n            ' args_schema={'properties': {'metrics': {'items': {'type': 'string'}, 'title': 'Metrics', 'type': 'array'}}, 'required': ['metrics'], 'title': 'get_metrics_infoArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4d228c0>\n",
      "‚úÖ TOOL: name='get_tables_list' description='\\n            Get general info of all the table in the database.\\n            Returns:\\n                str: Tables Information.\\n            ' args_schema={'properties': {}, 'title': 'get_tables_listArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4d22950>\n",
      "‚úÖ TOOL: name='PCA_tool' description='\\n            Tool: Perform PCA analysis. Returns a dict with status and output file or error message.\\n            ' args_schema={'properties': {'input_file_name': {'title': 'Input File Name', 'type': 'string'}, 'output_file_name': {'title': 'Output File Name', 'type': 'string'}, 'n_components': {'default': 2, 'title': 'N Components', 'type': 'integer'}}, 'required': ['input_file_name', 'output_file_name'], 'title': 'PCA_toolArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4cdd3f0>\n",
      "‚úÖ TOOL: name='similarity_tool' description='\\n            Tool: Compute similarity scores. Returns a dict with status and output file or error message.\\n            ' args_schema={'properties': {'input_file_name': {'title': 'Input File Name', 'type': 'string'}, 'output_file_name': {'title': 'Output File Name', 'type': 'string'}, 'metric': {'enum': ['cosine', 'euclidean'], 'title': 'Metric', 'type': 'string'}}, 'required': ['input_file_name', 'output_file_name', 'metric'], 'title': 'similarity_toolArguments', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x772bd4cddab0>\n",
      "‚úÖ TOOL: <class 'src.schemas.Done'>\n"
     ]
    }
   ],
   "source": [
    "from src.agent import Builder\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "genai_model=ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    google_api_key=\"AIzaSyABT5kXMTABmM50mgANfpYVNY7KeqAmbak\"\n",
    ")\n",
    "builder = await Builder.create(genai_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a34236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ GRAPH STATE:\n",
      "To measure the efficiency of attackers, consider the following metrics:\n",
      "- **Non-Penalty Goals per 90 (npg/90)**: Measures goals scored from open play per 90 minutes.\n",
      "- **Shots on target %**: Percentage of shots that are on target.\n",
      "- **Goals minus xG (G-xG)**: Measures finishing ability compared to chance quality.\n",
      "- **Progressive Passes Received**: Measures how often attackers receive the ball in advanced areas.\n",
      "- **Dribbles Completed %**: Percentage of completed dribbles.\n",
      "- **Touches in Opponent's Box per 90**: Measures a player's presence in dangerous attacking areas.\n",
      "üîÅ GRAPH STATE:\n",
      "\n",
      "\n",
      "First, I need to access the database to retrieve descriptions of these metrics.\n",
      "‚ùå TOOL: LLM returned wrong content format at tool_call step ‚Äî can't proceed to tool_node.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to invoke tool: LLM returned wrong content format at tool_call step ‚Äî can't proceed to tool_node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/soccer_analysis/src/agent.py:106\u001b[0m, in \u001b[0;36mBuilder.llm_tool_call\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM returned wrong content format at tool_call step ‚Äî can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt proceed to tool_node.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: LLM returned wrong content format at tool_call step ‚Äî can't proceed to tool_node.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[1;32m      3\u001b[0m init_state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are some efficient attackers of 2024-2025 season\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mastream(init_state):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîÅ GRAPH STATE:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s[\u001b[38;5;28mlist\u001b[39m(s\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/soccer_analysis/env/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2655\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mamatch_cached_writes():\n\u001b[1;32m   2654\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2655\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   2656\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2657\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2658\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2659\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maaccept_push,\n\u001b[1;32m   2660\u001b[0m ):\n\u001b[1;32m   2661\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2662\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   2663\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/soccer_analysis/env/lib/python3.10/site-packages/langgraph/pregel/runner.py:294\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    292\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    295\u001b[0m         t,\n\u001b[1;32m    296\u001b[0m         retry_policy,\n\u001b[1;32m    297\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    298\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    299\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    300\u001b[0m                 _acall,\n\u001b[1;32m    301\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    302\u001b[0m                 stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    303\u001b[0m                 retry\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    304\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    305\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[1;32m    306\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    307\u001b[0m                 loop\u001b[38;5;241m=\u001b[39mloop,\n\u001b[1;32m    308\u001b[0m             ),\n\u001b[1;32m    309\u001b[0m         },\n\u001b[1;32m    310\u001b[0m     )\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/soccer_analysis/env/lib/python3.10/site-packages/langgraph/pregel/retry.py:136\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policies, stream, match_cached_writes, configurable)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    138\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/soccer_analysis/env/lib/python3.10/site-packages/langgraph/utils/runnable.py:676\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    673\u001b[0m                 step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    674\u001b[0m             )\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 676\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/soccer_analysis/env/lib/python3.10/site-packages/langgraph/utils/runnable.py:440\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/soccer_analysis/src/agent.py:109\u001b[0m, in \u001b[0;36mBuilder.llm_tool_call\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå TOOL:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to invoke tool: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to invoke tool: LLM returned wrong content format at tool_call step ‚Äî can't proceed to tool_node."
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "init_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What are some efficient attackers of 2024-2025 season\")]\n",
    "}\n",
    "\n",
    "async for s in builder.graph.astream(init_state):\n",
    "    print(\"üîÅ CURRENT STATE:\")\n",
    "    print(s[list(s.keys())[0]][\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9178b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(graph, xray=False):\n",
    "    \"\"\"Display a LangGraph mermaid diagram with fallback rendering.\n",
    "    \n",
    "    Handles timeout errors from mermaid.ink by falling back to pyppeteer.\n",
    "    \n",
    "    Args:\n",
    "        graph: The LangGraph object that has a get_graph() method\n",
    "    \"\"\"\n",
    "    from IPython.display import Image\n",
    "    try:\n",
    "        # Try the default renderer first\n",
    "        return Image(graph.get_graph(xray=xray).draw_mermaid_png())\n",
    "    except Exception as e:\n",
    "        # Fall back to pyppeteer if the default renderer fails\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "        return Image(graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.PYPPETEER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdec1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(builder.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643249ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is the best all-round footballer of 2024-2025?\"\n",
    "init_state = {\"messages\": [{\"role\": \"user\", \"content\": question}]}\n",
    "\n",
    "# 1) plain / non-stream run\n",
    "state = await builder.graph.ainvoke(init_state)      # <- this returns a dict\n",
    "print(state[\"messages\"][-1])                          # last AIMessage\n",
    "print(state[\"messages\"][-1].tool_calls)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d1d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae5749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc3e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a659c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "X = [[0, 0, 0], [1, 1, 1], [0.5, 1, 0.5]]\n",
    "sim_matrix=cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccabccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_names=[\"mot\", \"hai\", \"ba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_scores = pd.DataFrame(sim_matrix, index=player_names, columns=player_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0049cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM \"2018_2019\" AS st17\n",
    "LEFT JOIN \"possession_2018_2019\" AS ps17\n",
    "  ON st17.Player = ps17.Player AND st17.Squad = ps17.Squad AND st17.Nation = ps17.Nation\n",
    "LEFT JOIN \"gca_2018_2019\" AS gca17\n",
    "  ON st17.Player = gca17.Player AND st17.Squad = gca17.Squad AND st17.Nation = gca17.Nation\n",
    "'''\n",
    "df = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ff75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e87a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pos'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    (\n",
    "        (df['Pos'] =='MF,FW') | \n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8586066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "features = ['npxG+xAG_90','Att 3rd', 'Succ','Succ%', 'Carries', 'PrgDist', 'SCA90', 'GCA90','PassLive_90']\n",
    "X_values = df[features].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(X_values)\n",
    "                \n",
    "pca_converter = PCA(n_components=2)\n",
    "principal_components = pca_converter.fit_transform(scaled_values)\n",
    "pca_df = pd.DataFrame(principal_components, columns=['PCA1', 'PCA2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dedf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pca_df[\n",
    "    (\n",
    "        (pca_df['PCA1'] >= df['PCA1'].max() * 0.65) | (pca_df['PCA2'] >= pca_df['PCA2'].max() * 0.65)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Min-Max normalization\n",
    "df['xAG_norm'] = (df['xAG'] - df['xAG'].min()) / (df['xAG'].max() - df['xAG'].min())\n",
    "df['PrgC_norm'] = (df['PrgC'] - df['PrgC'].min()) / (df['PrgC'].max() - df['PrgC'].min())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.scatterplot(data=df, x='xAG_norm', y='PrgC_norm')\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ax.text(x=row['xAG_norm'], y=row['PrgC_norm'] - 0.03, s=row['Player'], fontsize=8, ha='center', va='center')\n",
    "\n",
    "ax.set_xlabel('xAG (normalized)')\n",
    "ax.set_ylabel('PrgC (normalized)')\n",
    "plt.title('Normalized Scatterplot of xAG vs PrgC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
